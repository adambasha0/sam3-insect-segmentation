{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ae428f-eb69-4bde-b63a-96eb1dedb1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching best dilation...\n",
      "\n",
      "Dilation 12: TP=592, FP=36, FN=13, Precision=0.9427, Recall=0.9785, F1=0.9603\n",
      "Dilation 13: TP=593, FP=35, FN=12, Precision=0.9443, Recall=0.9802, F1=0.9619\n",
      "Dilation 14: TP=591, FP=37, FN=14, Precision=0.9411, Recall=0.9769, F1=0.9586\n",
      "Dilation 15: TP=587, FP=41, FN=19, Precision=0.9347, Recall=0.9686, F1=0.9514\n",
      "Dilation 16: TP=587, FP=41, FN=19, Precision=0.9347, Recall=0.9686, F1=0.9514\n",
      "Dilation 17: TP=581, FP=47, FN=25, Precision=0.9252, Recall=0.9587, F1=0.9417\n",
      "Dilation 18: TP=577, FP=51, FN=29, Precision=0.9188, Recall=0.9521, F1=0.9352\n",
      "Dilation 19: TP=575, FP=53, FN=32, Precision=0.9156, Recall=0.9473, F1=0.9312\n",
      "Dilation 20: TP=567, FP=61, FN=40, Precision=0.9029, Recall=0.9341, F1=0.9182\n",
      "Dilation 21: TP=559, FP=69, FN=48, Precision=0.8901, Recall=0.9209, F1=0.9053\n",
      "Dilation 22: TP=551, FP=77, FN=56, Precision=0.8774, Recall=0.9077, F1=0.8923\n",
      "Dilation 23: TP=536, FP=92, FN=71, Precision=0.8535, Recall=0.8830, F1=0.8680\n",
      "Dilation 24: TP=523, FP=105, FN=83, Precision=0.8328, Recall=0.8630, F1=0.8476\n",
      "Dilation 25: TP=507, FP=121, FN=99, Precision=0.8073, Recall=0.8366, F1=0.8217\n",
      "\n",
      "✅ Best dilation: 13, F1=0.9619\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pycocotools import mask as maskUtils\n",
    "import cv2\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "gt_json_path = \"./flatbug-dataset/cao2022/instances_default.json\"\n",
    "pred_json_path = \"./flatbug-dataset/cao2022/sam3_results.json\"\n",
    "IOU_THRESHOLD = 0.5\n",
    "MAX_DILATION = 25 # max pixels to try\n",
    "\n",
    "# =========================\n",
    "# UTILS\n",
    "# =========================\n",
    "def dilate_mask(mask, dilation_pixels=3):\n",
    "    kernel = np.ones((dilation_pixels, dilation_pixels), np.uint8)\n",
    "    return cv2.dilate(mask.astype(np.uint8), kernel, iterations=1)\n",
    "\n",
    "def mask_from_seg(segmentation, h, w):\n",
    "    rle = maskUtils.frPyObjects(segmentation, h, w)\n",
    "    mask = maskUtils.decode(rle)\n",
    "    if len(mask.shape) == 3:\n",
    "        mask = np.any(mask, axis=2)\n",
    "    return mask.astype(np.uint8)\n",
    "\n",
    "def compute_metrics(pred_masks, gt_masks, iou_thresh=0.5):\n",
    "    TP = FP = FN = 0\n",
    "    matched_gt = set()\n",
    "\n",
    "    for p_mask in pred_masks:\n",
    "        # ensure proper type for pycocotools\n",
    "        p_mask_enc = maskUtils.encode(np.asfortranarray(p_mask.astype(np.uint8)))\n",
    "        ious = []\n",
    "        for g_mask in gt_masks:\n",
    "            g_mask_enc = maskUtils.encode(np.asfortranarray(g_mask.astype(np.uint8)))\n",
    "            iou_val = maskUtils.iou([p_mask_enc], [g_mask_enc], [0])[0]\n",
    "            ious.append(iou_val)\n",
    "\n",
    "        if len(ious) == 0:\n",
    "            FP += 1\n",
    "            continue\n",
    "\n",
    "        max_iou_idx = np.argmax(ious)\n",
    "        if ious[max_iou_idx] >= iou_thresh:\n",
    "            TP += 1\n",
    "            matched_gt.add(max_iou_idx)\n",
    "        else:\n",
    "            FP += 1\n",
    "\n",
    "    FN = len(gt_masks) - len(matched_gt)\n",
    "    precision = TP / (TP + FP + 1e-6)\n",
    "    recall = TP / (TP + FN + 1e-6)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "    return TP, FP, FN, precision, recall, f1\n",
    "\n",
    "# =========================\n",
    "# LOAD JSON\n",
    "# =========================\n",
    "with open(gt_json_path) as f:\n",
    "    gt_data = json.load(f)\n",
    "\n",
    "with open(pred_json_path) as f:\n",
    "    pred_data = json.load(f)\n",
    "\n",
    "# -------------------------\n",
    "# Map image_id → (height, width)\n",
    "# -------------------------\n",
    "image_sizes = {img[\"id\"]: (img[\"height\"], img[\"width\"]) for img in gt_data[\"images\"]}\n",
    "\n",
    "# -------------------------\n",
    "# Load GT masks\n",
    "# -------------------------\n",
    "gt_by_image = {}\n",
    "for ann in gt_data[\"annotations\"]:\n",
    "    img_id = ann[\"image_id\"]\n",
    "    h, w = image_sizes[img_id]\n",
    "    mask = mask_from_seg(ann[\"segmentation\"], h, w)\n",
    "    gt_by_image.setdefault(img_id, []).append(mask)\n",
    "\n",
    "# -------------------------\n",
    "# Load predicted masks\n",
    "# -------------------------\n",
    "pred_by_image = {}\n",
    "for ann in pred_data[\"annotations\"]:\n",
    "    img_id = ann[\"image_id\"]\n",
    "    h, w = image_sizes[img_id]\n",
    "    mask = mask_from_seg(ann[\"segmentation\"], h, w)\n",
    "    pred_by_image.setdefault(img_id, []).append(mask)\n",
    "\n",
    "# =========================\n",
    "# SEARCH BEST DILATION\n",
    "# =========================\n",
    "best_f1 = 0\n",
    "best_dilation = 0\n",
    "\n",
    "print(\"\\nSearching best dilation...\\n\")\n",
    "\n",
    "for dilation in range(12, MAX_DILATION + 1):\n",
    "    total_TP = total_FP = total_FN = 0\n",
    "    for img_id, gt_masks in gt_by_image.items():\n",
    "        pred_masks = pred_by_image.get(img_id, [])\n",
    "        # apply dilation\n",
    "        pred_masks_dilated = [dilate_mask(m, dilation) for m in pred_masks]\n",
    "        TP, FP, FN, _, _, _ = compute_metrics(pred_masks_dilated, gt_masks, IOU_THRESHOLD)\n",
    "        total_TP += TP\n",
    "        total_FP += FP\n",
    "        total_FN += FN\n",
    "\n",
    "    precision = total_TP / (total_TP + total_FP + 1e-6)\n",
    "    recall = total_TP / (total_TP + total_FN + 1e-6)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "\n",
    "    print(f\"Dilation {dilation}: TP={total_TP}, FP={total_FP}, FN={total_FN}, \"\n",
    "          f\"Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_dilation = dilation\n",
    "\n",
    "print(f\"\\n✅ Best dilation: {best_dilation}, F1={best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ba1f2-bd0d-460b-abe8-01824c6d68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from pycocotools import mask as maskUtils\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# ==========================\n",
    "# CONFIG\n",
    "# ==========================\n",
    "root_dataset = \"./flatbug-dataset\"\n",
    "output_overlay_root = \"./dilated_metrics\"\n",
    "\n",
    "datasets_to_eval = {\n",
    "    \"nhm-beetles-crops\",\n",
    "    \"cao2022\",\n",
    "    \"gernat2018\",\n",
    "    \"sittinger2023\",\n",
    "    \"amarathunga2022\",\n",
    "    \"biodiscover-arm\",\n",
    "}\n",
    "\n",
    "IOU_THRESHOLD = 0.5\n",
    "MAX_DILATION = 50\n",
    "NUM_VIS_IMAGES = 2  # number of images to visualize per dataset\n",
    "\n",
    "# ==========================\n",
    "# UTILITIES\n",
    "# ==========================\n",
    "def seg_to_rle_mask(segmentation, H, W):\n",
    "    if segmentation is None:\n",
    "        return np.zeros((H, W), dtype=np.uint8)\n",
    "    if isinstance(segmentation, dict):\n",
    "        return maskUtils.decode(segmentation).astype(np.uint8)\n",
    "    if isinstance(segmentation, list):\n",
    "        rle = maskUtils.frPyObjects(segmentation, H, W)\n",
    "        rle = maskUtils.merge(rle)\n",
    "        return maskUtils.decode(rle).astype(np.uint8)\n",
    "    return np.zeros((H, W), dtype=np.uint8)\n",
    "\n",
    "def dilate_mask(mask, dilation_pixels):\n",
    "    if dilation_pixels <= 0:\n",
    "        return mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilation_pixels, dilation_pixels))\n",
    "    return cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "def compute_metrics(pred_masks, gt_masks, iou_thresh=0.5):\n",
    "    TP = FP = 0\n",
    "    matched_gt = set()\n",
    "    for p_mask in pred_masks:\n",
    "        if p_mask is None:\n",
    "            continue\n",
    "        p_mask_rle = maskUtils.encode(np.asfortranarray(p_mask.astype(np.uint8)))\n",
    "        ious = []\n",
    "        for g_mask in gt_masks:\n",
    "            if g_mask is None:\n",
    "                continue\n",
    "            g_mask_rle = maskUtils.encode(np.asfortranarray(g_mask.astype(np.uint8)))\n",
    "            iou_val = maskUtils.iou([p_mask_rle], [g_mask_rle], [0])[0]\n",
    "            ious.append(iou_val)\n",
    "        if not ious or max(ious) < iou_thresh:\n",
    "            FP += 1\n",
    "        else:\n",
    "            best_idx = np.argmax(ious)\n",
    "            if best_idx not in matched_gt:\n",
    "                TP += 1\n",
    "                matched_gt.add(best_idx)\n",
    "            else:\n",
    "                FP += 1\n",
    "    FN = len(gt_masks) - len(matched_gt)\n",
    "    precision = TP / (TP + FP + 1e-6)\n",
    "    recall = TP / (TP + FN + 1e-6)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "    return TP, FP, FN, precision, recall, f1\n",
    "\n",
    "def overlay_masks_on_image(image_path, gt_masks, pred_masks, save_path):\n",
    "    \"\"\"\n",
    "    Overlay GT and Pred masks on original image, distinct colors, labels.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    overlay = Image.new(\"RGBA\", image.size, (0,0,0,0))\n",
    "    draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "    # colors\n",
    "    gt_color = (0,255,0,120)      # semi-transparent green\n",
    "    pred_color = (30,144,255,120) # semi-transparent blue\n",
    "\n",
    "    # draw GT masks\n",
    "    for m in gt_masks:\n",
    "        ys, xs = np.where(m>0)\n",
    "        for x, y in zip(xs, ys):\n",
    "            draw.point((x,y), fill=gt_color)\n",
    "\n",
    "    # draw Pred masks\n",
    "    for m in pred_masks:\n",
    "        ys, xs = np.where(m>0)\n",
    "        for x, y in zip(xs, ys):\n",
    "            draw.point((x,y), fill=pred_color)\n",
    "\n",
    "    # composite and add labels\n",
    "    final = Image.alpha_composite(image.convert(\"RGBA\"), overlay)\n",
    "    draw_final = ImageDraw.Draw(final)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    draw_final.text((10,10), \"GT\", fill=(0,255,0), font=font)\n",
    "    draw_final.text((10,35), \"Pred\", fill=(30,144,255), font=font)\n",
    "\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    final.convert(\"RGB\").save(save_path)\n",
    "\n",
    "# ==========================\n",
    "# MAIN LOOP\n",
    "# ==========================\n",
    "best_dilations = {}\n",
    "\n",
    "for dataset_name in sorted(os.listdir(root_dataset)):\n",
    "    if dataset_name.lower() not in datasets_to_eval:\n",
    "        continue\n",
    "\n",
    "    dataset_path = os.path.join(root_dataset, dataset_name)\n",
    "    gt_file = os.path.join(dataset_path, \"instances_default.json\")\n",
    "    pred_file = os.path.join(dataset_path, \"sam3_results.json\")\n",
    "\n",
    "    if not os.path.isfile(gt_file) or not os.path.isfile(pred_file):\n",
    "        print(f\"❌ Missing GT or SAM3 predictions in {dataset_name}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n======================\\nEvaluating dataset: {dataset_name}\\n======================\")\n",
    "\n",
    "    gt_data = json.load(open(gt_file))\n",
    "    pred_data = json.load(open(pred_file))\n",
    "\n",
    "    # map annotations per image\n",
    "    gt_by_image = defaultdict(list)\n",
    "    image_sizes = {}\n",
    "    image_file_map = {}\n",
    "    for im in gt_data[\"images\"]:\n",
    "        image_sizes[im[\"id\"]] = (im[\"height\"], im[\"width\"])\n",
    "        image_file_map[im[\"id\"]] = os.path.join(dataset_path, im[\"file_name\"])\n",
    "    for ann in gt_data[\"annotations\"]:\n",
    "        gt_by_image[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "    pred_by_image = defaultdict(list)\n",
    "    for ann in pred_data[\"annotations\"]:\n",
    "        pred_by_image[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "    # search for best dilation\n",
    "    best_f1 = -1\n",
    "    best_dilation = 0\n",
    "    f1_history = []\n",
    "\n",
    "    dilation = 0\n",
    "    while dilation <= MAX_DILATION:\n",
    "        TP_total = FP_total = FN_total = 0\n",
    "\n",
    "        for img_id, gt_objs in gt_by_image.items():\n",
    "            H, W = image_sizes[img_id]\n",
    "            gt_masks = [seg_to_rle_mask(g[\"segmentation\"], H, W) for g in gt_objs]\n",
    "            pred_objs = pred_by_image.get(img_id, [])\n",
    "            pred_masks = [dilate_mask(seg_to_rle_mask(p[\"segmentation\"], H, W), dilation) for p in pred_objs]\n",
    "\n",
    "            TP, FP, FN, _, _, _ = compute_metrics(pred_masks, gt_masks, IOU_THRESHOLD)\n",
    "            TP_total += TP\n",
    "            FP_total += FP\n",
    "            FN_total += FN\n",
    "\n",
    "        precision = TP_total / (TP_total + FP_total + 1e-6)\n",
    "        recall = TP_total / (TP_total + FN_total + 1e-6)\n",
    "        f1_score = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "        f1_history.append(f1_score)\n",
    "\n",
    "        print(f\"Dilation {dilation}: TP={TP_total}, FP={FP_total}, FN={FN_total}, Precision={precision:.4f}, Recall={recall:.4f}, F1={f1_score:.4f}\")\n",
    "\n",
    "        # stop if F1 decreasing for 2 consecutive steps\n",
    "        if len(f1_history) >= 3:\n",
    "            if f1_history[-1] < f1_history[-2] < f1_history[-3]:\n",
    "                break\n",
    "\n",
    "        if f1_score > best_f1:\n",
    "            best_f1 = f1_score\n",
    "            best_dilation = dilation\n",
    "\n",
    "        dilation += 1\n",
    "\n",
    "    best_dilations[dataset_name] = best_dilation\n",
    "    print(f\"✅ Best dilation for {dataset_name}: {best_dilation}, F1={best_f1:.4f}\")\n",
    "\n",
    "    # ==========================\n",
    "    # SAVE VISUAL OVERLAYS FOR 2 IMAGES\n",
    "    # ==========================\n",
    "    save_overlay_path = os.path.join(output_overlay_root, dataset_name)\n",
    "    saved_count = 0\n",
    "    for img_id, gt_objs in gt_by_image.items():\n",
    "        if saved_count >= NUM_VIS_IMAGES:\n",
    "            break\n",
    "        H, W = image_sizes[img_id]\n",
    "        image_path = image_file_map[img_id]\n",
    "\n",
    "        gt_masks = [seg_to_rle_mask(g[\"segmentation\"], H, W) for g in gt_objs]\n",
    "        pred_objs = pred_by_image.get(img_id, [])\n",
    "        pred_masks = [dilate_mask(seg_to_rle_mask(p[\"segmentation\"], H, W), best_dilation) for p in pred_objs]\n",
    "\n",
    "        save_path = os.path.join(save_overlay_path, os.path.basename(image_path))\n",
    "        overlay_masks_on_image(image_path, gt_masks, pred_masks, save_path)\n",
    "        saved_count += 1\n",
    "\n",
    "# ==========================\n",
    "# Mean best dilation\n",
    "# ==========================\n",
    "mean_best_dilation = np.mean(list(best_dilations.values()))\n",
    "print(\"\\n======================\")\n",
    "print(\"Best dilations per dataset:\", best_dilations)\n",
    "print(f\"Mean best dilation across datasets: {mean_best_dilation:.2f}\")\n",
    "print(\"======================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sam3env)",
   "language": "python",
   "name": "sam3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
