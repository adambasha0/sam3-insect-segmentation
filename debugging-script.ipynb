{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c05a4ab-d231-4f7a-b03f-03b3139fe9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================\n",
      "FINAL SUMMARY\n",
      "=====================\n",
      "TP = 590\n",
      "FP = 229\n",
      "FN = 11\n",
      "\n",
      "Top images with most FN:\n",
      " image 9: 3 FN\n",
      " image 45: 2 FN\n",
      " image 3: 1 FN\n",
      " image 16: 1 FN\n",
      " image 20: 1 FN\n",
      " image 24: 1 FN\n",
      " image 35: 1 FN\n",
      " image 40: 1 FN\n",
      "\n",
      "Top images with most FP:\n",
      " image 8: 8 FP\n",
      " image 33: 8 FP\n",
      " image 59: 8 FP\n",
      " image 3: 7 FP\n",
      " image 57: 7 FP\n",
      " image 18: 6 FP\n",
      " image 24: 6 FP\n",
      " image 28: 6 FP\n",
      " image 40: 6 FP\n",
      " image 43: 6 FP\n",
      "\n",
      "Saved detailed debug info → debug_failures.json\n",
      "\n",
      "=====================\n",
      "FINAL SUMMARY\n",
      "=====================\n",
      "TP = 590\n",
      "FP = 229\n",
      "FN = 11\n",
      "\n",
      "--- METRICS ---\n",
      "Precision: 0.7204\n",
      "Recall:    0.9817\n",
      "F1 Score:  0.8310\n",
      "\n",
      "Top images with most FN:\n",
      " image 9: 3 FN\n",
      " image 45: 2 FN\n",
      " image 3: 1 FN\n",
      " image 16: 1 FN\n",
      " image 20: 1 FN\n",
      " image 24: 1 FN\n",
      " image 35: 1 FN\n",
      " image 40: 1 FN\n",
      "\n",
      "Top images with most FP:\n",
      " image 8: 8 FP\n",
      " image 33: 8 FP\n",
      " image 59: 8 FP\n",
      " image 3: 7 FP\n",
      " image 57: 7 FP\n",
      " image 18: 6 FP\n",
      " image 24: 6 FP\n",
      " image 28: 6 FP\n",
      " image 40: 6 FP\n",
      " image 43: 6 FP\n",
      "\n",
      "Saved detailed debug info → debug_failures.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "dataset_path = \"./flatbug-dataset/cao2022\"\n",
    "\n",
    "GT_JSON = os.path.join(dataset_path, \"instances_default.json\")\n",
    "PRED_JSON = os.path.join(dataset_path, \"sam3_results_tiled.json\")   # or SAM3 seg file\n",
    "\n",
    "IOU_THRESHOLD = 0.2\n",
    "USE_SEGMENTATION = True     # set True if evaluating segmentation IoU\n",
    "\n",
    "# ============================================================\n",
    "# IOU FUNCTIONS\n",
    "# ============================================================\n",
    "def bbox_iou(b1, b2):\n",
    "    x1,y1,w1,h1=b1\n",
    "    x2,y2,w2,h2=b2\n",
    "    xa=max(x1,x2); ya=max(y1,y2)\n",
    "    xb=min(x1+w1,x2+w2); yb=min(y1+h1,y2+h2)\n",
    "    inter=max(0,xb-xa)*max(0,yb-ya)\n",
    "    union=w1*h1 + w2*h2 - inter\n",
    "    return inter/union if union>0 else 0\n",
    "\n",
    "def seg_mask(seg, H, W):\n",
    "    \"\"\"Polygon -> mask or RLE -> mask. Same logic as your previous script.\"\"\"\n",
    "    if seg is None:\n",
    "        return None\n",
    "    if isinstance(seg, list):\n",
    "        mask = np.zeros((H, W), dtype=np.uint8)\n",
    "        for poly in seg:\n",
    "            try:\n",
    "                pts = np.array(poly).reshape(-1,2).astype(np.int32)\n",
    "                cv2.fillPoly(mask, [pts], 1)\n",
    "            except:\n",
    "                continue\n",
    "        return mask\n",
    "    if isinstance(seg, dict):\n",
    "        try:\n",
    "            from pycocotools import mask as mu\n",
    "            return mu.decode(seg)\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def seg_iou(m1, m2):\n",
    "    inter = np.logical_and(m1, m2).sum()\n",
    "    union = np.logical_or(m1, m2).sum()\n",
    "    return inter / union if union > 0 else 0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LOAD JSON\n",
    "# ============================================================\n",
    "gt = json.load(open(GT_JSON))\n",
    "pred = json.load(open(PRED_JSON))\n",
    "\n",
    "# group by image\n",
    "gt_by_image = defaultdict(list)\n",
    "pred_by_image = defaultdict(list)\n",
    "\n",
    "for g in gt[\"annotations\"]:\n",
    "    gt_by_image[g[\"image_id\"]].append(g)\n",
    "\n",
    "for p in pred[\"annotations\"]:\n",
    "    pred_by_image[p[\"image_id\"]].append(p)\n",
    "\n",
    "# image sizes (needed for seg IoU only)\n",
    "sizes = {im[\"id\"]: (im[\"height\"], im[\"width\"]) for im in gt[\"images\"]}\n",
    "\n",
    "# ============================================================\n",
    "# TRACK FN / FP per image\n",
    "# ============================================================\n",
    "FN_images = defaultdict(int)\n",
    "FP_images = defaultdict(int)\n",
    "\n",
    "FN_details = defaultdict(list)\n",
    "FP_details = defaultdict(list)\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "# ============================================================\n",
    "# MAIN LOOP\n",
    "# ============================================================\n",
    "for img_id in gt_by_image.keys():\n",
    "\n",
    "    gt_objs = gt_by_image[img_id]\n",
    "    pred_objs = sorted(pred_by_image.get(img_id, []), \n",
    "                       key=lambda x: x.get(\"score\",1.0), reverse=True)\n",
    "\n",
    "    matched_gt = set()\n",
    "\n",
    "    # prepare segmentation masks if needed\n",
    "    if USE_SEGMENTATION:\n",
    "        H,W = sizes[img_id]\n",
    "\n",
    "        gt_masks = [seg_mask(g[\"segmentation\"], H, W) for g in gt_objs]\n",
    "        pred_masks = [seg_mask(p[\"segmentation\"], H, W) for p in pred_objs]\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # match predictions to GT\n",
    "    # -----------------------------------------\n",
    "    for pi, p in enumerate(pred_objs):\n",
    "\n",
    "        best_iou = 0\n",
    "        best_gt = None\n",
    "\n",
    "        for gi, g in enumerate(gt_objs):\n",
    "            if gi in matched_gt:\n",
    "                continue\n",
    "            ##if p[\"category_id\"] != g[\"category_id\"]:\n",
    "              ##  continue\n",
    "\n",
    "            if USE_SEGMENTATION:\n",
    "                iou_val = seg_iou(pred_masks[pi], gt_masks[gi])\n",
    "            else:\n",
    "                iou_val = bbox_iou(p[\"bbox\"], g[\"bbox\"])\n",
    "\n",
    "            if iou_val > best_iou:\n",
    "                best_iou = iou_val\n",
    "                best_gt = gi\n",
    "\n",
    "        if best_iou >= IOU_THRESHOLD:\n",
    "            matched_gt.add(best_gt)\n",
    "            TP += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "            FP_images[img_id] += 1\n",
    "            FP_details[img_id].append({\n",
    "                \"pred_id\": p[\"id\"],\n",
    "                \"pred_bbox\": p.get(\"bbox\"),\n",
    "                \"score\": p.get(\"score\",1.0),\n",
    "                \"best_iou\": best_iou\n",
    "            })\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # GT not matched → FN\n",
    "    # -----------------------------------------\n",
    "    for gi, g in enumerate(gt_objs):\n",
    "        if gi not in matched_gt:\n",
    "            FN += 1\n",
    "            FN_images[img_id] += 1\n",
    "            FN_details[img_id].append({\n",
    "                \"gt_id\": g[\"id\"],\n",
    "                \"gt_bbox\": g.get(\"bbox\"),\n",
    "                \"category_id\": g[\"category_id\"]\n",
    "            })\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DISPLAY SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n=====================\")\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=====================\")\n",
    "print(\"TP =\", TP)\n",
    "print(\"FP =\", FP)\n",
    "print(\"FN =\", FN)\n",
    "\n",
    "print(\"\\nTop images with most FN:\")\n",
    "sorted_FN = sorted(FN_images.items(), key=lambda x: x[1], reverse=True)\n",
    "for img_id, count in sorted_FN[:10]:\n",
    "    print(f\" image {img_id}: {count} FN\")\n",
    "\n",
    "print(\"\\nTop images with most FP:\")\n",
    "sorted_FP = sorted(FP_images.items(), key=lambda x: x[1], reverse=True)\n",
    "for img_id, count in sorted_FP[:10]:\n",
    "    print(f\" image {img_id}: {count} FP\")\n",
    "\n",
    "# ============================================================\n",
    "# SAVE DETAILS TO JSON\n",
    "# ============================================================\n",
    "output = {\n",
    "    \"TP\": TP,\n",
    "    \"FP\": FP,\n",
    "    \"FN\": FN,\n",
    "    \"FN_images\": FN_images,\n",
    "    \"FP_images\": FP_images,\n",
    "    \"FN_details\": FN_details,\n",
    "    \"FP_details\": FP_details,\n",
    "}\n",
    "\n",
    "# convert defaultdict → normal dict\n",
    "output = json.loads(json.dumps(output, default=lambda x: dict(x)))\n",
    "\n",
    "with open(\"debug_failures.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=4)\n",
    "\n",
    "print(\"\\nSaved detailed debug info → debug_failures.json\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DISPLAY SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n=====================\")\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=====================\")\n",
    "print(\"TP =\", TP)\n",
    "print(\"FP =\", FP)\n",
    "print(\"FN =\", FN)\n",
    "\n",
    "# ----------------------------\n",
    "# METRICS\n",
    "# ----------------------------\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"\\n--- METRICS ---\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\nTop images with most FN:\")\n",
    "sorted_FN = sorted(FN_images.items(), key=lambda x: x[1], reverse=True)\n",
    "for img_id, count in sorted_FN[:10]:\n",
    "    print(f\" image {img_id}: {count} FN\")\n",
    "\n",
    "print(\"\\nTop images with most FP:\")\n",
    "sorted_FP = sorted(FP_images.items(), key=lambda x: x[1], reverse=True)\n",
    "for img_id, count in sorted_FP[:10]:\n",
    "    print(f\" image {img_id}: {count} FP\")\n",
    "\n",
    "# ============================================================\n",
    "# SAVE DETAILS TO JSON\n",
    "# ============================================================\n",
    "output = {\n",
    "    \"TP\": TP,\n",
    "    \"FP\": FP,\n",
    "    \"FN\": FN,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": f1,\n",
    "    \"FN_images\": FN_images,\n",
    "    \"FP_images\": FP_images,\n",
    "    \"FN_details\": FN_details,\n",
    "    \"FP_details\": FP_details,\n",
    "}\n",
    "\n",
    "# convert defaultdict → normal dict\n",
    "output = json.loads(json.dumps(output, default=lambda x: dict(x)))\n",
    "\n",
    "with open(\"debug_failures.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=4)\n",
    "\n",
    "print(\"\\nSaved detailed debug info → debug_failures.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7fd9845-0206-4e9a-bd5f-4f24454ce75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "def debug_visualize_annotation(dataset_path, image_id, output_folder=\"debug_output\"):\n",
    "    \"\"\"\n",
    "    dataset_path: path to dataset folder (contains images/ and instances_default.json)\n",
    "    image_id: integer or string (without extension)\n",
    "    \"\"\"\n",
    "    print(\"===================================\")\n",
    "    print(f\" Debug Visualizer\")\n",
    "    print(f\" Dataset: {dataset_path}\")\n",
    "    print(f\" Image ID: {image_id}\")\n",
    "    print(\"===================================\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Load JSON\n",
    "    # -------------------------------\n",
    "    json_path = os.path.join(dataset_path, \"instances_default.json\")\n",
    "\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"ERROR: JSON not found: {json_path}\")\n",
    "        return\n",
    "    \n",
    "    with open(json_path, \"r\") as f:\n",
    "        gt = json.load(f)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Find the image entry\n",
    "    # -------------------------------\n",
    "    image_entry = None\n",
    "    for img in gt[\"images\"]:\n",
    "        if str(img[\"id\"]) == str(image_id):\n",
    "            image_entry = img\n",
    "            break\n",
    "\n",
    "    if image_entry is None:\n",
    "        print(f\"ERROR: image_id {image_id} not found in JSON.\")\n",
    "        return\n",
    "    \n",
    "    img_path = os.path.join(dataset_path, image_entry[\"file_name\"])\n",
    "\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"ERROR: image file missing: {img_path}\")\n",
    "        return\n",
    "\n",
    "    # Load image\n",
    "    img = Image.open(img_path).convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(img, \"RGBA\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Find GT annotations for this image\n",
    "    # -------------------------------\n",
    "    ann_for_image = [ann for ann in gt[\"annotations\"] if ann[\"image_id\"] == image_entry[\"id\"]]\n",
    "\n",
    "    if len(ann_for_image) == 0:\n",
    "        print(\"WARNING: No annotations found for this image.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(ann_for_image)} annotations.\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Create mask canvas\n",
    "    # -------------------------------\n",
    "    W, H = image_entry[\"width\"], image_entry[\"height\"]\n",
    "    mask_canvas = Image.new(\"RGBA\", (W, H), (0, 0, 0, 0))\n",
    "    mask_draw = ImageDraw.Draw(mask_canvas, \"RGBA\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Draw annotations\n",
    "    # -------------------------------\n",
    "    for ann in ann_for_image:\n",
    "        # Draw bounding box\n",
    "        x, y, w, h = ann[\"bbox\"]\n",
    "        draw.rectangle([x, y, x + w, y + h], outline=(0, 255, 0, 255), width=3)\n",
    "\n",
    "        # Draw segmentation mask if polygon\n",
    "        seg = ann[\"segmentation\"]\n",
    "        \n",
    "        if isinstance(seg, list):  # polygon\n",
    "            for poly in seg:\n",
    "                mask_draw.polygon(poly, outline=(255, 0, 0, 255), fill=(255, 0, 0, 80))\n",
    "        else:\n",
    "            # if RLE encoded\n",
    "            rle = seg\n",
    "            if isinstance(rle, dict) and \"counts\" in rle:\n",
    "                m = maskUtils.decode(rle)\n",
    "                colored_mask = Image.new(\"RGBA\", (W, H), (255, 0, 0, 0))\n",
    "                pixels = colored_mask.load()\n",
    "                for i in range(W):\n",
    "                    for j in range(H):\n",
    "                        if m[j, i] == 1:\n",
    "                            pixels[i, j] = (255, 0, 0, 80)\n",
    "                img = Image.alpha_composite(img, colored_mask)\n",
    "\n",
    "    # Combine mask with image\n",
    "    img = Image.alpha_composite(img, mask_canvas)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Save output\n",
    "    # -------------------------------\n",
    "    out_dir = os.path.join(output_folder, os.path.basename(dataset_path))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    out_path = os.path.join(out_dir, f\"{image_id}.png\")\n",
    "    img.save(out_path)\n",
    "\n",
    "    print(f\"Saved visualization → {out_path}\")\n",
    "    print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da23463-5376-4aec-8cfc-3b0e9c6b5522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      " Debug Visualizer\n",
      " Dataset: ./flatbug-dataset/AMT\n",
      " Image ID: 104\n",
      "===================================\n",
      "Found 22 annotations.\n",
      "Saved visualization → debug_output/AMT/104.png\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "debug_visualize_annotation(\n",
    "    dataset_path=\"./flatbug-dataset/AMT\",\n",
    "    image_id=104\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c90e655-a273-496c-96d8-c95532a9576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "\n",
    "def visualize_gt_vs_pred(dataset_path,\n",
    "                         sam3_image_id,\n",
    "                         gt_json=\"instances_default.json\",\n",
    "                         pred_json=\"sam3_results.json\",\n",
    "                         output_folder=\"debug_output\"):\n",
    "\n",
    "    print(\"=============================================\")\n",
    "    print(\" VISUALIZING GT vs SAM3 PREDICTIONS\")\n",
    "    print(f\" Dataset: {dataset_path}\")\n",
    "    print(f\" SAM3 Image ID: {sam3_image_id}\")\n",
    "    print(\"=============================================\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Load GT\n",
    "    # -----------------------\n",
    "    gt_path = os.path.join(dataset_path, gt_json)\n",
    "    with open(gt_path, \"r\") as f:\n",
    "        gt = json.load(f)\n",
    "\n",
    "    # -----------------------\n",
    "    # Load SAM3\n",
    "    # -----------------------\n",
    "    pred_path = os.path.join(dataset_path, pred_json)\n",
    "    if not os.path.exists(pred_path):\n",
    "        print(\"ERROR: SAM3 predictions file not found:\", pred_path)\n",
    "        return\n",
    "\n",
    "    with open(pred_path, \"r\") as f:\n",
    "        preds_raw = json.load(f)\n",
    "\n",
    "    # Flexible SAM3 format\n",
    "    if isinstance(preds_raw, list):\n",
    "        preds = preds_raw\n",
    "    elif \"annotations\" in preds_raw:\n",
    "        preds = preds_raw[\"annotations\"]\n",
    "    elif \"predictions\" in preds_raw:\n",
    "        preds = preds_raw[\"predictions\"]\n",
    "    else:\n",
    "        raise ValueError(\"Cannot detect SAM3 format\")\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # NEW: Extract file_name from SAM3 first\n",
    "    # ---------------------------------------------------\n",
    "    sam3_items = [p for p in preds if str(p.get(\"image_id\")) == str(sam3_image_id)]\n",
    "\n",
    "    if len(sam3_items) == 0:\n",
    "        print(\"ERROR: No SAM3 predictions found for image_id:\", sam3_image_id)\n",
    "        print(\"Available first few:\",\n",
    "              [p.get(\"image_id\") for p in preds[:10]])\n",
    "        return\n",
    "\n",
    "    file_name = sam3_items[0].get(\"file_name\")\n",
    "    if not file_name:\n",
    "        print(\"ERROR: SAM3 entries missing `file_name`\")\n",
    "        return\n",
    "\n",
    "    print(f\"→ SAM3 file_name found: {file_name}\")\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Find matching GT image by file_name\n",
    "    # ---------------------------------------------------\n",
    "    img_entry = next((img for img in gt[\"images\"]\n",
    "                      if img[\"file_name\"] == file_name), None)\n",
    "\n",
    "    if img_entry is None:\n",
    "        print(\"ERROR: GT image not found for file_name:\", file_name)\n",
    "        return\n",
    "\n",
    "    W, H = img_entry[\"width\"], img_entry[\"height\"]\n",
    "    img_path = os.path.join(dataset_path, file_name)\n",
    "\n",
    "    if not os.path.exists(img_path):\n",
    "        print(\"ERROR: Image missing:\", img_path)\n",
    "        return\n",
    "\n",
    "    base_img = Image.open(img_path).convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(base_img, \"RGBA\")\n",
    "\n",
    "    mask_canvas = Image.new(\"RGBA\", (W, H), (0, 0, 0, 0))\n",
    "    mask_draw = ImageDraw.Draw(mask_canvas, \"RGBA\")\n",
    "\n",
    "    GT_COLOR = (0, 255, 0, 180)\n",
    "    PRED_COLOR = (0, 120, 255, 180)\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 22)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # GT annotations matching correct GT image\n",
    "    # ---------------------------------------------------\n",
    "    gt_anns = [a for a in gt[\"annotations\"]\n",
    "               if a[\"image_id\"] == img_entry[\"id\"]]\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # SAM3 annotations matching file_name (BEST)\n",
    "    # ---------------------------------------------------\n",
    "    pred_anns = [a for a in preds if a.get(\"file_name\") == file_name]\n",
    "\n",
    "    print(f\"GT objects  : {len(gt_anns)}\")\n",
    "    print(f\"SAM3 objects: {len(pred_anns)}\")\n",
    "\n",
    "    debug_info = {\n",
    "        \"file_name\": file_name,\n",
    "        \"gt\": [],\n",
    "        \"sam3\": []\n",
    "    }\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Draw GT\n",
    "    # ---------------------------------------------------\n",
    "    for ann in gt_anns:\n",
    "\n",
    "        seg = ann[\"segmentation\"]\n",
    "        debug_info[\"gt\"].append({\n",
    "            \"bbox\": ann[\"bbox\"],\n",
    "            \"segmentation\": ann[\"segmentation\"],\n",
    "            \"area\": ann.get(\"area\")\n",
    "        })\n",
    "\n",
    "        if isinstance(seg, list):\n",
    "            # polygon\n",
    "            for poly in seg:\n",
    "                mask_draw.polygon(poly, fill=(0,255,0,80))\n",
    "        else:\n",
    "            # RLE\n",
    "            mask = maskUtils.decode(seg)\n",
    "            ys, xs = np.where(mask == 1)\n",
    "            for x, y in zip(xs, ys):\n",
    "                mask_canvas.putpixel((x, y), (0,255,0,80))\n",
    "\n",
    "        x, y, w, h = ann[\"bbox\"]\n",
    "        draw.rectangle([x, y, x+w, y+h], outline=GT_COLOR, width=3)\n",
    "        draw.text((x, y - 12), \"GT\", fill=(0,255,0), font=font)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Draw SAM3\n",
    "    # ---------------------------------------------------\n",
    "    for ann in pred_anns:\n",
    "        seg = ann[\"segmentation\"]\n",
    "\n",
    "        debug_info[\"sam3\"].append({\n",
    "            \"bbox\": ann[\"bbox\"],\n",
    "            \"segmentation\": ann[\"segmentation\"],\n",
    "            \"score\": ann.get(\"score\"),\n",
    "            \"area\": ann.get(\"area\")\n",
    "        })\n",
    "\n",
    "        if isinstance(seg, list):\n",
    "            for poly in seg:\n",
    "                mask_draw.polygon(poly, fill=(0,120,255,80))\n",
    "        else:\n",
    "            if isinstance(seg, dict) and \"counts\" in seg:\n",
    "                mask = maskUtils.decode(seg)\n",
    "                ys, xs = np.where(mask == 1)\n",
    "                for x, y in zip(xs, ys):\n",
    "                    mask_canvas.putpixel((x, y), (0,120,255,80))\n",
    "\n",
    "        x, y, w, h = ann[\"bbox\"]\n",
    "        draw.rectangle([x, y, x+w, y+h], outline=PRED_COLOR, width=3)\n",
    "        draw.text((x, y - 12), \"SAM3\", fill=(0,120,255), font=font)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # Merge\n",
    "    # ---------------------------------------------------\n",
    "    final_img = Image.alpha_composite(base_img, mask_canvas)\n",
    "\n",
    "    out_dir = os.path.join(output_folder, os.path.basename(dataset_path))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    png_path = os.path.join(out_dir, f\"{sam3_image_id}.png\")\n",
    "    json_path = os.path.join(out_dir, f\"{sam3_image_id}.json\")\n",
    "\n",
    "    final_img.save(png_path)\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(debug_info, f, indent=2)\n",
    "\n",
    "    print(\"Saved:\", png_path)\n",
    "    print(\"Saved:\", json_path)\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc87ab8c-a290-4bab-87b5-adf3fe1fa6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      " VISUALIZING GT vs SAM3 PREDICTIONS\n",
      " Dataset: flatbug-dataset/cao2022/\n",
      " SAM3 Image ID: 13\n",
      "=============================================\n",
      "→ SAM3 file_name found: 000100.jpg\n",
      "GT objects  : 10\n",
      "SAM3 objects: 10\n",
      "Saved: debug_output/13.png\n",
      "Saved: debug_output/13.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "visualize_gt_vs_pred(\n",
    "  \"flatbug-dataset/cao2022/\",\n",
    "   13,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9311b268-2d90-4b09-8149-c10042107d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GT: 601\n",
      "Loaded Pred: 628\n",
      "\n",
      "=====================\n",
      " FINAL SUMMARY\n",
      "=====================\n",
      "TP = 280\n",
      "FP = 348\n",
      "FN = 321\n",
      "\n",
      "Top images with most FN:\n",
      "  ('000053.jpg', 10)\n",
      "  ('000103.jpg', 10)\n",
      "  ('000253.jpg', 10)\n",
      "  ('000002.jpg', 9)\n",
      "  ('000077.jpg', 9)\n",
      "  ('000301.jpg', 9)\n",
      "  ('000303.jpg', 9)\n",
      "  ('000325.jpg', 9)\n",
      "  ('000153.jpg', 8)\n",
      "  ('000202.jpg', 8)\n",
      "\n",
      "Top images with most FP:\n",
      "  ('000002.jpg', 10)\n",
      "  ('000053.jpg', 10)\n",
      "  ('000253.jpg', 10)\n",
      "  ('000325.jpg', 10)\n",
      "  ('000077.jpg', 9)\n",
      "  ('000103.jpg', 9)\n",
      "  ('000275.jpg', 9)\n",
      "  ('000303.jpg', 9)\n",
      "  ('000928.jpg', 9)\n",
      "  ('000003.jpg', 8)\n",
      "\n",
      "Saved → debug_failures_segmentation.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "dataset_path = \"./flatbug-dataset/cao2022\"\n",
    "\n",
    "GT_JSON = os.path.join(dataset_path, \"instances_default.json\")\n",
    "PRED_JSON = os.path.join(dataset_path, \"sam3_results.json\")\n",
    "\n",
    "IOU_THRESHOLD = 0.5\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MASK UTILITIES\n",
    "# ============================================================\n",
    "def polygons_to_mask(polygons, height, width):\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    for poly in polygons:\n",
    "        try:\n",
    "            pts = np.array(poly, dtype=np.int32).reshape(-1, 2)\n",
    "            cv2.fillPoly(mask, [pts], 1)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return mask\n",
    "\n",
    "\n",
    "def seg_to_mask(segmentation, height, width):\n",
    "    \"\"\"Convert COCO segmentation (polygons or RLE) to binary mask.\"\"\"\n",
    "    if segmentation is None:\n",
    "        return None\n",
    "\n",
    "    # polygon format\n",
    "    if isinstance(segmentation, list):\n",
    "        if len(segmentation) == 0:\n",
    "            return np.zeros((height, width), dtype=np.uint8)\n",
    "        return polygons_to_mask(segmentation, height, width)\n",
    "\n",
    "    # RLE\n",
    "    if isinstance(segmentation, dict):\n",
    "        try:\n",
    "            from pycocotools import mask as mask_utils\n",
    "            return mask_utils.decode(segmentation).astype(np.uint8)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def mask_iou(m1, m2):\n",
    "    inter = np.logical_and(m1, m2).sum()\n",
    "    union = np.logical_or(m1, m2).sum()\n",
    "    return float(inter) / float(union) if union > 0 else 0.0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LOAD JSON\n",
    "# ============================================================\n",
    "gt = json.load(open(GT_JSON))\n",
    "pred = json.load(open(PRED_JSON))\n",
    "\n",
    "print(\"Loaded GT:\", len(gt[\"annotations\"]))\n",
    "print(\"Loaded Pred:\", len(pred[\"annotations\"]))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# GROUP BY FILE NAME\n",
    "# ============================================================\n",
    "gt_by_file = defaultdict(list)\n",
    "sizes = {}\n",
    "\n",
    "for im in gt[\"images\"]:\n",
    "    sizes[im[\"file_name\"]] = (im[\"height\"], im[\"width\"])\n",
    "for g in gt[\"annotations\"]:\n",
    "    file_name = next(im[\"file_name\"] for im in gt[\"images\"] if im[\"id\"] == g[\"image_id\"])\n",
    "    gt_by_file[file_name].append(g)\n",
    "\n",
    "pred_by_file = defaultdict(list)\n",
    "for p in pred[\"annotations\"]:\n",
    "    file_name = p.get(\"file_name\")\n",
    "    if file_name:\n",
    "        pred_by_file[file_name].append(p)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DEBUG COUNTERS\n",
    "# ============================================================\n",
    "TP = FP = FN = 0\n",
    "FN_images = defaultdict(int)\n",
    "FP_images = defaultdict(int)\n",
    "\n",
    "FN_details = defaultdict(list)\n",
    "FP_details = defaultdict(list)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN LOOP\n",
    "# ============================================================\n",
    "for file_name, gt_objs in gt_by_file.items():\n",
    "\n",
    "    if file_name not in sizes:\n",
    "        print(f\"Skipping missing image size: {file_name}\")\n",
    "        continue\n",
    "\n",
    "    H, W = sizes[file_name]\n",
    "    pred_objs = pred_by_file.get(file_name, [])\n",
    "\n",
    "    # Construct masks\n",
    "    gt_masks = [seg_to_mask(g.get(\"segmentation\"), H, W) for g in gt_objs]\n",
    "    gt_cats = [g[\"category_id\"] for g in gt_objs]\n",
    "\n",
    "    pred_masks = [seg_to_mask(p.get(\"segmentation\"), H, W) for p in pred_objs]\n",
    "    pred_cats = [p[\"category_id\"] for p in pred_objs]\n",
    "    pred_scores = [p.get(\"score\", 1.0) for p in pred_objs]\n",
    "\n",
    "    matched_gt = set()\n",
    "\n",
    "    # Sort predictions by confidence\n",
    "    order = sorted(range(len(pred_objs)), key=lambda i: pred_scores[i], reverse=True)\n",
    "\n",
    "    for pi in order:\n",
    "        pmask = pred_masks[pi]\n",
    "        if pmask is None:\n",
    "            FP += 1\n",
    "            FP_images[file_name] += 1\n",
    "            FP_details[file_name].append({\n",
    "                \"pred_bbox\": pred_objs[pi].get(\"bbox\"),\n",
    "                \"score\": pred_scores[pi],\n",
    "                \"reason\": \"mask_none\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        pcat = pred_cats[pi]\n",
    "\n",
    "        best_iou = 0.0\n",
    "        best_gt = None\n",
    "\n",
    "        for gi, (gmask, gcat) in enumerate(zip(gt_masks, gt_cats)):\n",
    "            if gi in matched_gt:\n",
    "                continue\n",
    "            if gmask is None:\n",
    "                continue\n",
    "            ## if pcat != gcat:\n",
    "            ##   continue\n",
    "\n",
    "            iou = mask_iou(pmask, gmask)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_gt = gi\n",
    "\n",
    "        if best_iou >= IOU_THRESHOLD and best_gt is not None:\n",
    "            matched_gt.add(best_gt)\n",
    "            TP += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "            FP_images[file_name] += 1\n",
    "            FP_details[file_name].append({\n",
    "                \"pred_bbox\": pred_objs[pi].get(\"bbox\"),\n",
    "                \"score\": pred_scores[pi],\n",
    "                \"best_iou\": best_iou\n",
    "            })\n",
    "\n",
    "    # Remaining unmatched GT = FN\n",
    "    for gi, g in enumerate(gt_objs):\n",
    "        if gi not in matched_gt:\n",
    "            FN += 1\n",
    "            FN_images[file_name] += 1\n",
    "            FN_details[file_name].append({\n",
    "                \"gt_bbox\": g.get(\"bbox\"),\n",
    "                \"category_id\": g[\"category_id\"]\n",
    "            })\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n=====================\")\n",
    "print(\" FINAL SUMMARY\")\n",
    "print(\"=====================\")\n",
    "print(\"TP =\", TP)\n",
    "print(\"FP =\", FP)\n",
    "print(\"FN =\", FN)\n",
    "\n",
    "print(\"\\nTop images with most FN:\")\n",
    "for fn in sorted(FN_images.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(\" \", fn)\n",
    "\n",
    "print(\"\\nTop images with most FP:\")\n",
    "for fp in sorted(FP_images.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(\" \", fp)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SAVE TO JSON\n",
    "# ============================================================\n",
    "output = {\n",
    "    \"TP\": TP,\n",
    "    \"FP\": FP,\n",
    "    \"FN\": FN,\n",
    "    \"FN_images\": dict(FN_images),\n",
    "    \"FP_images\": dict(FP_images),\n",
    "    \"FN_details\": {k: v for k, v in FN_details.items()},\n",
    "    \"FP_details\": {k: v for k, v in FP_details.items()},\n",
    "}\n",
    "\n",
    "with open(\"debug_failures_segmentation.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=4)\n",
    "\n",
    "print(\"\\nSaved → debug_failures_segmentation.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa2a0f05-a422-4d13-b1e3-f469ea7ee3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# Decode segmentation mask\n",
    "# ===========================================================\n",
    "def decode_mask(segmentation, height, width):\n",
    "    \"\"\"Decode COCO RLE or polygon segmentation to binary mask.\"\"\"\n",
    "    if isinstance(segmentation, list):   # polygon\n",
    "        rle = maskUtils.frPyObjects(segmentation, height, width)\n",
    "        rle = maskUtils.merge(rle)\n",
    "    else:                                # RLE\n",
    "        rle = segmentation\n",
    "    return maskUtils.decode(rle)\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# Draw bounding box + label (Pillow 10+ compatible)\n",
    "# ===========================================================\n",
    "def draw_bbox(draw, bbox, outline_color, label_text, label_bg, font):\n",
    "    x, y, w, h = bbox\n",
    "    x2, y2 = x + w, y + h\n",
    "\n",
    "    # rectangle\n",
    "    draw.rectangle([x, y, x2, y2], outline=outline_color, width=3)\n",
    "\n",
    "    # compute text size (new Pillow API)\n",
    "    try:\n",
    "        l, t, r, b = font.getbbox(label_text)\n",
    "        tw, th = r - l, b - t\n",
    "    except:\n",
    "        # fallback old versions\n",
    "        tw, th = draw.textsize(label_text, font=font)\n",
    "\n",
    "    # label background\n",
    "    draw.rectangle([x, y - th - 2, x + tw + 4, y], fill=label_bg)\n",
    "\n",
    "    # label text\n",
    "    draw.text((x + 2, y - th - 2), label_text, fill=\"white\", font=font)\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# Overlay segmentation mask\n",
    "# ===========================================================\n",
    "def overlay_segmentation(image, mask, color):\n",
    "    rgba = Image.new(\"RGBA\", image.size)\n",
    "    overlay = ImageDraw.Draw(rgba)\n",
    "\n",
    "    ys, xs = np.where(mask == 1)\n",
    "\n",
    "    # semi-transparent\n",
    "    for x, y in zip(xs, ys):\n",
    "        overlay.point((x, y), fill=color + (90,))   # RGBA with alpha\n",
    "\n",
    "    return Image.alpha_composite(image.convert(\"RGBA\"), rgba)\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# Main visualization function\n",
    "# ===========================================================\n",
    "def visualize_selected_images(\n",
    "    dataset_path,\n",
    "    gt_json_path,\n",
    "    pred_json_path,\n",
    "    output_folder,\n",
    "    selected_images\n",
    "):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load JSONs\n",
    "    with open(gt_json_path, \"r\") as f:\n",
    "        gt_data = json.load(f)\n",
    "    with open(pred_json_path, \"r\") as f:\n",
    "        pred_data = json.load(f)\n",
    "\n",
    "    # Build image_id → file_name dictionary\n",
    "    gt_id_to_file = {img[\"id\"]: img[\"file_name\"] for img in gt_data[\"images\"]}\n",
    "    pred_id_to_file = {img[\"id\"]: img[\"file_name\"] for img in pred_data[\"images\"]}\n",
    "\n",
    "    # Build file_name → annotations map\n",
    "    gt_by_file = {}\n",
    "    pred_by_file = {}\n",
    "\n",
    "    for ann in gt_data[\"annotations\"]:\n",
    "        fname = gt_id_to_file[ann[\"image_id\"]]\n",
    "        gt_by_file.setdefault(fname, []).append(ann)\n",
    "\n",
    "    for ann in pred_data[\"annotations\"]:\n",
    "        fname = pred_id_to_file[ann[\"image_id\"]]\n",
    "        pred_by_file.setdefault(fname, []).append(ann)\n",
    "\n",
    "    # Load font\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Colors\n",
    "    GT_COLOR = (0, 255, 0)      # green\n",
    "    SAM_COLOR = (0, 100, 255)   # blue\n",
    "\n",
    "    # Process each selected image\n",
    "    for file_name in selected_images:\n",
    "        print(f\"Processing {file_name} ...\")\n",
    "\n",
    "        img_path = os.path.join(dataset_path, file_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            print(\" ❌ Image missing:\", img_path)\n",
    "            continue\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGBA\")\n",
    "        H, W = image.height, image.width\n",
    "\n",
    "        # all annotations for that file\n",
    "        gt_anns = gt_by_file.get(file_name, [])\n",
    "        pred_anns = pred_by_file.get(file_name, [])\n",
    "\n",
    "        # JSON output\n",
    "        debug_json = {\n",
    "            \"file_name\": file_name,\n",
    "            \"gt\": [],\n",
    "            \"sam3\": []\n",
    "        }\n",
    "\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        # ---- GT Overlays ----\n",
    "        for ann in gt_anns:\n",
    "            mask = decode_mask(ann[\"segmentation\"], H, W)\n",
    "            image = overlay_segmentation(image, mask, GT_COLOR)\n",
    "            draw_bbox(draw, ann[\"bbox\"], GT_COLOR, \"GT\", (0, 150, 0), font)\n",
    "\n",
    "            debug_json[\"gt\"].append({\n",
    "                \"bbox\": ann[\"bbox\"],\n",
    "                \"segmentation\": ann[\"segmentation\"]\n",
    "            })\n",
    "\n",
    "        # ---- SAM3 Overlays ----\n",
    "        for ann in pred_anns:\n",
    "            mask = decode_mask(ann[\"segmentation\"], H, W)\n",
    "            image = overlay_segmentation(image, mask, SAM_COLOR)\n",
    "            draw_bbox(draw, ann[\"bbox\"], SAM_COLOR, \"SAM3\", (0, 60, 180), font)\n",
    "\n",
    "            debug_json[\"sam3\"].append({\n",
    "                \"bbox\": ann[\"bbox\"],\n",
    "                \"segmentation\": ann[\"segmentation\"]\n",
    "            })\n",
    "\n",
    "        # Save visualization\n",
    "        out_img_path = os.path.join(output_folder, file_name)\n",
    "        image.convert(\"RGB\").save(out_img_path)\n",
    "\n",
    "        # Save JSON\n",
    "        debug_json_path = os.path.join(output_folder, file_name.replace(\".jpg\", \".json\"))\n",
    "        with open(debug_json_path, \"w\") as f:\n",
    "            json.dump(debug_json, f, indent=2)\n",
    "\n",
    "    print(\"\\n✅ DONE — Output saved in:\", output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fca66b92-fdbf-49d8-b754-1835177d6bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 2023-07-06_22_20_03.jpg.jpg\n",
      " Missing image: flatbug-dataset/Mothitor/2023-07-06_22_20_03.jpg.jpg\n",
      "Processing: 2023-07-07_23_00_03.jpg\n",
      " Saved: debug_output/cao2022/2023-07-07_23_00_03.jpg and debug_output/cao2022/2023-07-07_23_00_03.json\n",
      "Processing: 2023-08-29_23_00_17.jpg\n",
      " Saved: debug_output/cao2022/2023-08-29_23_00_17.jpg and debug_output/cao2022/2023-08-29_23_00_17.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "## debug output with label of BB and seg mask of both sam3 and gt\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "dataset_path = \"flatbug-dataset/Mothitor\"\n",
    "gt_json_path = os.path.join(dataset_path, \"instances_default.json\")\n",
    "pred_json_path = os.path.join(dataset_path, \"sam3_results_pyramid.json\")\n",
    "output_folder = \"debug_output/Mothitor\"\n",
    "selected_images = [\"2023-07-06_22_20_03.jpg\", \"2023-07-07_23_00_03.jpg\", \"2023-08-29_23_00_17.jpg\"]\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Colors (BGR) and alpha\n",
    "GT_COLOR = (0, 200, 0)      # green\n",
    "SAM_COLOR = (220, 100, 10)  # orange-ish blue alternative in BGR\n",
    "ALPHA = 0.45                # mask transparency\n",
    "\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.6\n",
    "FONT_THICK = 1\n",
    "\n",
    "\n",
    "# ---------- utils ----------\n",
    "def decode_mask(seg, H, W):\n",
    "    \"\"\"\n",
    "    seg: polygon list or RLE dict (COCO format)\n",
    "    returns: binary mask (H,W) dtype=np.uint8 with 1 where object is\n",
    "    \"\"\"\n",
    "    if seg is None:\n",
    "        return None\n",
    "    # polygon(s)\n",
    "    if isinstance(seg, list):\n",
    "        # pycocotools expects a list of polygons; frPyObjects handles lists of polys\n",
    "        try:\n",
    "            rles = maskUtils.frPyObjects(seg, H, W)\n",
    "            if isinstance(rles, list):\n",
    "                rle = maskUtils.merge(rles)\n",
    "            else:\n",
    "                rle = rles\n",
    "            mask = maskUtils.decode(rle)\n",
    "            # decode returns shape (H,W) or (H,W,1)\n",
    "            if mask.ndim == 3:\n",
    "                mask = mask[:, :, 0]\n",
    "            return (mask > 0).astype(np.uint8)\n",
    "        except Exception:\n",
    "            # fallback: try rasterizing polygons with cv2\n",
    "            mask = np.zeros((H, W), dtype=np.uint8)\n",
    "            for poly in seg:\n",
    "                try:\n",
    "                    pts = np.array(poly, dtype=np.int32).reshape(-1, 2)\n",
    "                    cv2.fillPoly(mask, [pts], 1)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            return mask\n",
    "    # RLE dict\n",
    "    if isinstance(seg, dict):\n",
    "        try:\n",
    "            mask = maskUtils.decode(seg)\n",
    "            if mask.ndim == 3:\n",
    "                mask = mask[:, :, 0]\n",
    "            return (mask > 0).astype(np.uint8)\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def blend_mask_on_image(image, mask, color, alpha=0.45):\n",
    "    \"\"\"\n",
    "    image: BGR uint8\n",
    "    mask: binary uint8 (H,W)\n",
    "    color: BGR tuple\n",
    "    returns blended image (modified copy)\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        return image\n",
    "    overlay = image.copy().astype(np.float32)\n",
    "    colored = np.zeros_like(overlay, dtype=np.uint8)\n",
    "    colored[:, :] = color\n",
    "    # apply only where mask==1\n",
    "    mask3 = np.stack([mask] * 3, axis=-1).astype(bool)\n",
    "    overlay[mask3] = overlay[mask3] * (1 - alpha) + colored[mask3] * alpha\n",
    "    return overlay.astype(np.uint8)\n",
    "\n",
    "\n",
    "def draw_bbox_with_label(image, bbox, color, label):\n",
    "    \"\"\"\n",
    "    image: BGR uint8\n",
    "    bbox: [x,y,w,h]\n",
    "    draws rectangle and label on image in-place\n",
    "    \"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    x1, y1 = int(x), int(y)\n",
    "    x2, y2 = int(x + w), int(y + h)\n",
    "\n",
    "    # rectangle\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness=2)\n",
    "\n",
    "    # label background: compute text size\n",
    "    ((tw, th), _) = cv2.getTextSize(label, FONT, FONT_SCALE, FONT_THICK)\n",
    "    # ensure label sits above box; if not enough space, put inside top-left corner of box\n",
    "    label_x1 = x1\n",
    "    label_y1 = y1 - th - 6\n",
    "    label_y2 = y1\n",
    "    if label_y1 < 0:\n",
    "        label_y1 = y1\n",
    "        label_y2 = y1 + th + 6\n",
    "\n",
    "    cv2.rectangle(image, (label_x1, label_y1), (label_x1 + tw + 8, label_y2), color, thickness=-1)\n",
    "    # put white text\n",
    "    text_x = label_x1 + 4\n",
    "    text_y = label_y2 - 4 if label_y1 < label_y2 else label_y1 + th + 2\n",
    "    cv2.putText(image, label, (text_x, text_y), FONT, FONT_SCALE, (255, 255, 255), FONT_THICK, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "# ---------- load JSONs and build lookups ----------\n",
    "with open(gt_json_path, \"r\") as f:\n",
    "    gt = json.load(f)\n",
    "with open(pred_json_path, \"r\") as f:\n",
    "    pred = json.load(f)\n",
    "\n",
    "# Build id->file and file->image info\n",
    "gt_id_to_file = {img[\"id\"]: img[\"file_name\"] for img in gt[\"images\"]}\n",
    "gt_file_to_size = {img[\"file_name\"]: (img.get(\"height\"), img.get(\"width\")) for img in gt[\"images\"]}\n",
    "\n",
    "pred_id_to_file = {img[\"id\"]: img[\"file_name\"] for img in pred[\"images\"]}\n",
    "pred_file_to_size = {img[\"file_name\"]: (img.get(\"height\"), img.get(\"width\")) for img in pred[\"images\"]}\n",
    "\n",
    "gt_by_file = {}\n",
    "for ann in gt[\"annotations\"]:\n",
    "    fname = gt_id_to_file.get(ann[\"image_id\"])\n",
    "    if fname is None:\n",
    "        continue\n",
    "    gt_by_file.setdefault(fname, []).append(ann)\n",
    "\n",
    "pred_by_file = {}\n",
    "for ann in pred[\"annotations\"]:\n",
    "    fname = pred_id_to_file.get(ann[\"image_id\"])\n",
    "    if fname is None:\n",
    "        continue\n",
    "    pred_by_file.setdefault(fname, []).append(ann)\n",
    "\n",
    "\n",
    "# ---------- process selected images ----------\n",
    "for file_name in selected_images:\n",
    "    img_path = os.path.join(dataset_path, file_name)\n",
    "    print(\"Processing:\", file_name)\n",
    "    if not os.path.exists(img_path):\n",
    "        print(\" Missing image:\", img_path)\n",
    "        continue\n",
    "\n",
    "    # read image (BGR)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(\" Failed to read:\", img_path)\n",
    "        continue\n",
    "    H, W = img.shape[:2]\n",
    "\n",
    "    # copy for drawing\n",
    "    vis = img.copy()\n",
    "\n",
    "    # collect debug info\n",
    "    debug_json = {\"file_name\": file_name, \"gt\": [], \"sam3\": []}\n",
    "\n",
    "    # draw GT first (so SAM3 overlays on top if overlapping)\n",
    "    for ann in gt_by_file.get(file_name, []):\n",
    "        bbox = ann.get(\"bbox\")\n",
    "        seg = ann.get(\"segmentation\")\n",
    "        mask = decode_mask(seg, H, W) if seg is not None else None\n",
    "\n",
    "        if mask is not None:\n",
    "            vis = blend_mask_on_image(vis, mask, GT_COLOR, alpha=ALPHA)\n",
    "        if bbox:\n",
    "            draw_bbox_with_label(vis, bbox, GT_COLOR, \"GT\")\n",
    "\n",
    "        debug_json[\"gt\"].append({\n",
    "            \"id\": ann.get(\"id\"),\n",
    "            \"bbox\": bbox,\n",
    "            \"category_id\": ann.get(\"category_id\"),\n",
    "            \"has_mask\": mask is not None,\n",
    "            \"segmentation\": seg\n",
    "        })\n",
    "\n",
    "    # draw SAM3 predictions\n",
    "    for ann in pred_by_file.get(file_name, []):\n",
    "        bbox = ann.get(\"bbox\")\n",
    "        seg = ann.get(\"segmentation\")\n",
    "        mask = decode_mask(seg, H, W) if seg is not None else None\n",
    "\n",
    "        if mask is not None:\n",
    "            vis = blend_mask_on_image(vis, mask, SAM_COLOR, alpha=ALPHA)\n",
    "        if bbox:\n",
    "            draw_bbox_with_label(vis, bbox, SAM_COLOR, \"SAM3\")\n",
    "\n",
    "        debug_json[\"sam3\"].append({\n",
    "            \"id\": ann.get(\"id\"),\n",
    "            \"bbox\": bbox,\n",
    "            \"score\": ann.get(\"score\"),\n",
    "            \"category_id\": ann.get(\"category_id\"),\n",
    "            \"has_mask\": mask is not None,\n",
    "            \"segmentation\": seg\n",
    "        })\n",
    "\n",
    "    # write output image and JSON\n",
    "    out_img_path = os.path.join(output_folder, file_name)\n",
    "    cv2.imwrite(out_img_path, vis)\n",
    "\n",
    "    out_json_path = os.path.join(output_folder, file_name.replace(\".jpg\", \".json\"))\n",
    "    with open(out_json_path, \"w\") as jf:\n",
    "        json.dump(debug_json, jf, indent=2)\n",
    "\n",
    "    print(\" Saved:\", out_img_path, \"and\", out_json_path)\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f37afc3-e308-45cc-a4c9-4b64650a0f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET                        | FP COUNT   | MEAN FP SCORE  \n",
      "-----------------------------------------------------------------\n",
      "cao2022                        | 229        | 0.6248\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "==========================================\n",
      " GLOBAL FP SCORE ANALYSIS \n",
      "==========================================\n",
      "Total FPs analyzed:   229\n",
      "Global Mean FP Score: 0.6248\n",
      "Global Median Score:  0.5977\n",
      "Score Range:          0.4531 - 0.9062\n",
      "\n",
      "Saved detailed analysis to → fp_scores_analysis.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "root_dataset = \"./flatbug-dataset\"\n",
    "\n",
    "# List of datasets to evaluate\n",
    "datasets_to_eval = [\n",
    "    \"abram2023\", \"ALUS\", \"amarathunga2022\", \"AMI-traps\", \"AMT\", \"anTraX\",\n",
    "    \"ArTaxOr\", \"biodiscover-arm\", \"BIOSCAN\", \"cao2022\", \"CollembolAI\",\n",
    "    \"Diopsis\", \"DIRT\", \"DiversityScanner\", \"gernat2018\", \"Mothitor\",\n",
    "    \"NHM-beetles-crops\", \"PeMaToEuroPep\", \"pinoy2023\", \"sittinger2023\",\n",
    "    \"sticky-pi\", \"ubc-pitfall-traps\", \"ubc-scanned-sticky-cards\"\n",
    "]\n",
    "\n",
    "IOU_THRESHOLD = 0.2\n",
    "USE_SEGMENTATION = True      # set True if evaluating segmentation IoU\n",
    "\n",
    "# ============================================================\n",
    "# IOU HELPER FUNCTIONS\n",
    "# ============================================================\n",
    "def bbox_iou(b1, b2):\n",
    "    x1, y1, w1, h1 = b1\n",
    "    x2, y2, w2, h2 = b2\n",
    "    xa = max(x1, x2); ya = max(y1, y2)\n",
    "    xb = min(x1+w1, x2+w2); yb = min(y1+h1, y2+h2)\n",
    "    inter = max(0, xb - xa) * max(0, yb - ya)\n",
    "    union = w1*h1 + w2*h2 - inter\n",
    "    return inter / union if union > 0 else 0\n",
    "\n",
    "def seg_mask(seg, H, W):\n",
    "    if seg is None: return None\n",
    "    if isinstance(seg, list):\n",
    "        mask = np.zeros((H, W), dtype=np.uint8)\n",
    "        for poly in seg:\n",
    "            try:\n",
    "                pts = np.array(poly).reshape(-1, 2).astype(np.int32)\n",
    "                cv2.fillPoly(mask, [pts], 1)\n",
    "            except: continue\n",
    "        return mask\n",
    "    if isinstance(seg, dict):\n",
    "        try:\n",
    "            from pycocotools import mask as mu\n",
    "            return mu.decode(seg)\n",
    "        except: return None\n",
    "    return None\n",
    "\n",
    "def seg_iou(m1, m2):\n",
    "    inter = np.logical_and(m1, m2).sum()\n",
    "    union = np.logical_or(m1, m2).sum()\n",
    "    return inter / union if union > 0 else 0\n",
    "\n",
    "# ============================================================\n",
    "# GLOBAL ACCUMULATORS\n",
    "# ============================================================\n",
    "global_fp_scores = []\n",
    "dataset_stats = {}\n",
    "\n",
    "print(f\"{'DATASET':<30} | {'FP COUNT':<10} | {'MEAN FP SCORE':<15}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# ============================================================\n",
    "# MAIN DATASET LOOP\n",
    "# ============================================================\n",
    "for dataset_name in datasets_to_eval:\n",
    "    dataset_path = os.path.join(root_dataset, dataset_name)\n",
    "    \n",
    "    GT_JSON = os.path.join(dataset_path, \"instances_default.json\")\n",
    "    PRED_JSON = os.path.join(dataset_path, \"sam3_results_tiled.json\")\n",
    "\n",
    "    # Skip if files don't exist\n",
    "    if not os.path.exists(GT_JSON) or not os.path.exists(PRED_JSON):\n",
    "        # print(f\"⚠️  Skipping {dataset_name} (files missing)\")\n",
    "        continue\n",
    "\n",
    "    # Load JSONs\n",
    "    with open(GT_JSON) as f: gt = json.load(f)\n",
    "    with open(PRED_JSON) as f: pred = json.load(f)\n",
    "\n",
    "    # Group by image\n",
    "    gt_by_image = defaultdict(list)\n",
    "    pred_by_image = defaultdict(list)\n",
    "    sizes = {im[\"id\"]: (im[\"height\"], im[\"width\"]) for im in gt[\"images\"]}\n",
    "\n",
    "    for g in gt[\"annotations\"]:\n",
    "        gt_by_image[g[\"image_id\"]].append(g)\n",
    "\n",
    "    for p in pred[\"annotations\"]:\n",
    "        pred_by_image[p[\"image_id\"]].append(p)\n",
    "\n",
    "    # Local accumulators for this dataset\n",
    "    local_fp_scores = []\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # PROCESS IMAGES IN CURRENT DATASET\n",
    "    # -----------------------------------------\n",
    "    for img_id in gt_by_image.keys():\n",
    "        gt_objs = gt_by_image[img_id]\n",
    "        # Sort predictions by score descending\n",
    "        pred_objs = sorted(pred_by_image.get(img_id, []), \n",
    "                           key=lambda x: x.get(\"score\", 0.0), reverse=True)\n",
    "\n",
    "        matched_gt = set()\n",
    "\n",
    "        # Prepare masks if segmentation is enabled\n",
    "        if USE_SEGMENTATION:\n",
    "            H, W = sizes[img_id]\n",
    "            gt_masks = [seg_mask(g[\"segmentation\"], H, W) for g in gt_objs]\n",
    "            pred_masks = [seg_mask(p[\"segmentation\"], H, W) for p in pred_objs]\n",
    "\n",
    "        # Match predictions\n",
    "        for pi, p in enumerate(pred_objs):\n",
    "            best_iou = 0\n",
    "            best_gt = None\n",
    "\n",
    "            for gi, g in enumerate(gt_objs):\n",
    "                if gi in matched_gt: continue\n",
    "                # Optional: check category_id if strict class matching is needed\n",
    "                # if p.get(\"category_id\") != g.get(\"category_id\"): continue\n",
    "\n",
    "                if USE_SEGMENTATION:\n",
    "                    iou_val = seg_iou(pred_masks[pi], gt_masks[gi])\n",
    "                else:\n",
    "                    iou_val = bbox_iou(p[\"bbox\"], g[\"bbox\"])\n",
    "\n",
    "                if iou_val > best_iou:\n",
    "                    best_iou = iou_val\n",
    "                    best_gt = gi\n",
    "\n",
    "            # ----------------------------------\n",
    "            # DETERMINE TP / FP\n",
    "            # ----------------------------------\n",
    "            score = p.get(\"score\", 0.0)\n",
    "\n",
    "            if best_iou >= IOU_THRESHOLD:\n",
    "                # True Positive\n",
    "                matched_gt.add(best_gt)\n",
    "            else:\n",
    "                # False Positive\n",
    "                local_fp_scores.append(score)\n",
    "                global_fp_scores.append(score)\n",
    "\n",
    "    # Calculate mean for this dataset\n",
    "    if local_fp_scores:\n",
    "        mean_score = np.mean(local_fp_scores)\n",
    "        count = len(local_fp_scores)\n",
    "    else:\n",
    "        mean_score = 0.0\n",
    "        count = 0\n",
    "\n",
    "    dataset_stats[dataset_name] = {\n",
    "        \"count\": count,\n",
    "        \"mean_score\": mean_score\n",
    "    }\n",
    "\n",
    "    print(f\"{dataset_name:<30} | {count:<10} | {mean_score:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# FINAL GLOBAL REPORT\n",
    "# ============================================================\n",
    "print(\"-\" * 65)\n",
    "print(\"\\n==========================================\")\n",
    "print(\" GLOBAL FP SCORE ANALYSIS \")\n",
    "print(\"==========================================\")\n",
    "\n",
    "if global_fp_scores:\n",
    "    global_mean = np.mean(global_fp_scores)\n",
    "    global_median = np.median(global_fp_scores)\n",
    "    global_min = np.min(global_fp_scores)\n",
    "    global_max = np.max(global_fp_scores)\n",
    "    \n",
    "    print(f\"Total FPs analyzed:   {len(global_fp_scores)}\")\n",
    "    print(f\"Global Mean FP Score: {global_mean:.4f}\")\n",
    "    print(f\"Global Median Score:  {global_median:.4f}\")\n",
    "    print(f\"Score Range:          {global_min:.4f} - {global_max:.4f}\")\n",
    "else:\n",
    "    print(\"No False Positives found across any dataset.\")\n",
    "\n",
    "# ============================================================\n",
    "# OPTIONAL: SAVE RAW SCORES\n",
    "# ============================================================\n",
    "# If you want to plot a histogram later, saving the raw list is useful\n",
    "with open(\"fp_scores_analysis.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"global_mean\": global_mean if global_fp_scores else 0,\n",
    "        \"dataset_stats\": dataset_stats,\n",
    "        \"all_fp_scores\": global_fp_scores\n",
    "    }, f, indent=4)\n",
    "\n",
    "print(\"\\nSaved detailed analysis to → fp_scores_analysis.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf2bf46-3017-4b10-95ee-3829435dc68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# find mean sam3 score of FP\n",
    "# ============================================================\n",
    "\n",
    "# List of datasets to evaluate\n",
    "datasets_to_eval = [\n",
    "    \"amarathunga2022\", \"biodiscover-arm\",\n",
    "    \"NHM-beetles-crops\", \"sittinger2023\", \"gernat2018\",\n",
    "    ## \"PeMaToEuroPep\", \"ArTaxOr\", \"BIOSCAN\",\n",
    "    ##\"sticky-pi\", \"pinoy2023\", \"cao2022\", \"Diopsis\", \"DIRT\",  \"Mothitor\", \"abram2023\", \"ALUS\",\n",
    "    ## \"AMI-traps\", \"AMT\", \"anTraX\",\n",
    "    ## \"CollembolAI\", \"DiversityScanner\", \"ubc-pitfall-traps\", \"ubc-scanned-sticky-cards\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f78806-5666-40c8-867a-0ab77e6146c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET                   | FP COUNT   | MEAN SCORE\n",
      "------------------------------------------------------------\n",
      "amarathunga2022           | 23         | 0.6038\n",
      "biodiscover-arm           | 510        | 0.6246\n",
      "NHM-beetles-crops         | 848        | 0.7231\n",
      "sittinger2023             | 65         | 0.6662\n",
      "gernat2018                | 417        | 0.7228\n",
      "------------------------------------------------------------\n",
      "Global Mean FP Score: 0.6926\n",
      "Total FPs: 1863\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "root_dataset = \"./flatbug-dataset\"\n",
    "\n",
    "datasets_to_eval = [\n",
    "    ## \"amarathunga2022\",\n",
    "    ## \"NHM-beetles-crops\", \"sittinger2023\", \"gernat2018\", \"cao2022\"\n",
    "     \"PeMaToEuroPep\", \"ArTaxOr\", \"BIOSCAN\", \"Mothitor\", \"DIRT\", \"abram2023\",\n",
    "     \"Diopsis\", \"AMI-traps\", \"AMT\", \"anTraX\", \"biodiscover-arm\",\n",
    "    ## \"ALUS\",\n",
    "    ##\"sticky-pi\", \"pinoy2023\",\n",
    "    ## \"CollembolAI\", \"DiversityScanner\", \"ubc-pitfall-traps\", \"ubc-scanned-sticky-cards\",\n",
    "]\n",
    "\n",
    "IOU_THRESHOLD = 0.5 \n",
    "\n",
    "# ============================================================\n",
    "# UTILITIES\n",
    "# ============================================================\n",
    "def normalize_name(fname):\n",
    "    \"\"\"Strips paths to ensure matching works: 'data/img.jpg' -> 'img.jpg'\"\"\"\n",
    "    return os.path.basename(fname) if fname else None\n",
    "\n",
    "def polygons_to_mask(polygons, height, width):\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    for poly in polygons:\n",
    "        if not poly: continue\n",
    "        try:\n",
    "            pts = np.array(poly, dtype=np.int32).reshape(-1, 2)\n",
    "            cv2.fillPoly(mask, [pts], 1)\n",
    "        except: continue\n",
    "    return mask\n",
    "\n",
    "def seg_to_mask(segmentation, height, width):\n",
    "    if segmentation is None or not segmentation:\n",
    "        return np.zeros((height, width), dtype=np.uint8)\n",
    "    if isinstance(segmentation, list):\n",
    "        if isinstance(segmentation[0], (int, float)): return np.zeros((height, width), dtype=np.uint8)\n",
    "        return polygons_to_mask(segmentation, height, width)\n",
    "    if isinstance(segmentation, dict):\n",
    "        try:\n",
    "            from pycocotools import mask as mask_utils\n",
    "            return mask_utils.decode(segmentation).astype(np.uint8)\n",
    "        except: return np.zeros((height, width), dtype=np.uint8)\n",
    "    return np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "def mask_iou(mask1, mask2):\n",
    "    inter = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    return float(inter) / float(union) if union > 0 else 0.0\n",
    "\n",
    "# ============================================================\n",
    "# MAIN LOOP\n",
    "# ============================================================\n",
    "global_fp_scores = []\n",
    "dataset_stats = {}\n",
    "\n",
    "print(f\"{'DATASET':<25} | {'FP COUNT':<10} | {'MEAN SCORE':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for dataset_name in datasets_to_eval:\n",
    "    dataset_path = os.path.join(root_dataset, dataset_name)\n",
    "    gt_file = os.path.join(dataset_path, \"instances_default.json\")\n",
    "    \n",
    "    # Attempt to find sam3 results\n",
    "    pred_file = os.path.join(dataset_path, \"sam3_results_tiled.json\")\n",
    "    if not os.path.exists(pred_file):\n",
    "        pred_file = os.path.join(dataset_path, \"sam3_results.json\")\n",
    "\n",
    "    if not os.path.exists(gt_file) or not os.path.exists(pred_file):\n",
    "        # print(f\"Skipping {dataset_name} (files missing)\")\n",
    "        continue\n",
    "\n",
    "    # Load JSONs\n",
    "    with open(gt_file, 'r') as f: gt = json.load(f)\n",
    "    with open(pred_file, 'r') as f: pred = json.load(f)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # DEBUG: CHECK FILE MAPPING\n",
    "    # -------------------------------------------------\n",
    "    # Map GT ID -> File Name (Normalized)\n",
    "    gt_id_to_info = {}\n",
    "    gt_filenames_set = set()\n",
    "    \n",
    "    for im in gt.get(\"images\", []):\n",
    "        norm_name = normalize_name(im[\"file_name\"])\n",
    "        gt_id_to_info[im[\"id\"]] = {\n",
    "            \"file_name\": norm_name,\n",
    "            \"height\": im[\"height\"],\n",
    "            \"width\": im[\"width\"]\n",
    "        }\n",
    "        gt_filenames_set.add(norm_name)\n",
    "\n",
    "    # Map Pred ID -> File Name (Normalized)\n",
    "    pred_id_to_filename = {}\n",
    "    for im in pred.get(\"images\", []):\n",
    "        pred_id_to_filename[im[\"id\"]] = normalize_name(im[\"file_name\"])\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # ORGANIZE ANNOTATIONS BY FILE NAME\n",
    "    # -------------------------------------------------\n",
    "    gt_by_file = defaultdict(list)\n",
    "    for ann in gt.get(\"annotations\", []):\n",
    "        img_id = ann.get(\"image_id\")\n",
    "        if img_id in gt_id_to_info:\n",
    "            fname = gt_id_to_info[img_id][\"file_name\"]\n",
    "            gt_by_file[fname].append(ann)\n",
    "\n",
    "    pred_by_file = defaultdict(list)\n",
    "    pred_filenames_set = set()\n",
    "    \n",
    "    for ann in pred.get(\"annotations\", []):\n",
    "        # Try to get filename from annotation, fallback to image_id lookup\n",
    "        fname = normalize_name(ann.get(\"file_name\"))\n",
    "        if not fname:\n",
    "            fname = pred_id_to_filename.get(ann.get(\"image_id\"))\n",
    "        \n",
    "        if fname:\n",
    "            pred_by_file[fname].append(ann)\n",
    "            pred_filenames_set.add(fname)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # LOUD DEBUGGING\n",
    "    # -------------------------------------------------\n",
    "    common_files = gt_filenames_set.intersection(pred_filenames_set)\n",
    "    \n",
    "    if len(common_files) == 0:\n",
    "        print(f\"\\n[DEBUG] ⚠️  {dataset_name}: NO MATCHING FILES FOUND!\")\n",
    "        print(f\"   GT Sample:   {list(gt_filenames_set)[:3]}\")\n",
    "        print(f\"   Pred Sample: {list(pred_filenames_set)[:3]}\")\n",
    "        continue # Skip this dataset if no files match\n",
    "        \n",
    "    # Optional: Print match stats if suspicious\n",
    "    # print(f\"[DEBUG] {dataset_name}: Matched {len(common_files)} images.\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # EVALUATION LOGIC\n",
    "    # -------------------------------------------------\n",
    "    local_fp_scores = []\n",
    "    \n",
    "    for file_name in common_files:\n",
    "        gt_objs = gt_by_file[file_name]\n",
    "        pred_objs = pred_by_file[file_name]\n",
    "        \n",
    "        if not pred_objs: continue\n",
    "\n",
    "        H = gt_id_to_info[next(k for k,v in gt_id_to_info.items() if v[\"file_name\"] == file_name)][\"height\"]\n",
    "        W = gt_id_to_info[next(k for k,v in gt_id_to_info.items() if v[\"file_name\"] == file_name)][\"width\"]\n",
    "\n",
    "        # Convert GT to masks\n",
    "        gt_masks = [seg_to_mask(g.get(\"segmentation\"), H, W) for g in gt_objs]\n",
    "        \n",
    "        # Prepare Predictions\n",
    "        # Sort by score desc\n",
    "        pred_data = []\n",
    "        for p in pred_objs:\n",
    "            mask = seg_to_mask(p.get(\"segmentation\"), H, W)\n",
    "            score = p.get(\"score\", 0.0)\n",
    "            pred_data.append({\"mask\": mask, \"score\": score})\n",
    "        \n",
    "        pred_data.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "        matched_gt_indices = set()\n",
    "\n",
    "        for p in pred_data:\n",
    "            p_mask = p[\"mask\"]\n",
    "            best_iou = 0.0\n",
    "            best_gt_idx = None\n",
    "\n",
    "            for i, g_mask in enumerate(gt_masks):\n",
    "                if i in matched_gt_indices: continue\n",
    "                iou = mask_iou(p_mask, g_mask)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = i\n",
    "            \n",
    "            if best_iou >= IOU_THRESHOLD:\n",
    "                matched_gt_indices.add(best_gt_idx)\n",
    "            else:\n",
    "                # This is a FP\n",
    "                local_fp_scores.append(p[\"score\"])\n",
    "                global_fp_scores.append(p[\"score\"])\n",
    "\n",
    "    # Stats\n",
    "    count = len(local_fp_scores)\n",
    "    mean_score = np.mean(local_fp_scores) if count > 0 else 0.0\n",
    "    \n",
    "    print(f\"{dataset_name:<25} | {count:<10} | {mean_score:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================\n",
    "print(\"-\" * 60)\n",
    "if global_fp_scores:\n",
    "    print(f\"Global Mean FP Score: {np.mean(global_fp_scores):.4f}\")\n",
    "    print(f\"Total FPs: {len(global_fp_scores)}\")\n",
    "else:\n",
    "    print(\"No False Positives found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5e612f-6129-4b80-9aa6-7e98a85c3b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing impact of raising Confidence Threshold to: 0.6926\n",
      "\n",
      "DATASET                   | TOTAL TPs  | LOST TPs   | % LOST    \n",
      "-----------------------------------------------------------------\n",
      "ArTaxOr                   | 1101       | 81         | 7.4%\n",
      "BIOSCAN                   | 494        | 9          | 1.8%\n",
      "biodiscover-arm           | 2541       | 1551       | 61.0%\n",
      "-----------------------------------------------------------------\n",
      "TOTAL TPs FOUND:     4136\n",
      "TPs LOST (<= 0.6926): 1641\n",
      "GLOBAL LOSS RATE:    39.68%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# this script focuses on True Positives (TP). It collects the confidence scores of all successfully matched predictions (TPs) and counts how many of them fall \n",
    "## below Mean FP Score threshold calculated (0.6926). \n",
    "## These are the detections we would lose (turning them into False Negatives) if we filter by that score.\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "root_dataset = \"./flatbug-dataset\"\n",
    "\n",
    "datasets_to_eval = [\n",
    "    ## \"amarathunga2022\",\n",
    "    ## \"NHM-beetles-crops\", \"sittinger2023\", \"gernat2018\", \"cao2022\"\n",
    "     \"PeMaToEuroPep\", \"ArTaxOr\", \"BIOSCAN\", \"Mothitor\", \"DIRT\", \"abram2023\",\n",
    "     \"Diopsis\", \"AMI-traps\", \"AMT\", \"anTraX\", \"biodiscover-arm\",\n",
    "    ## \"ALUS\",\n",
    "    ##\"sticky-pi\", \"pinoy2023\",\n",
    "    ## \"CollembolAI\", \"DiversityScanner\", \"ubc-pitfall-traps\", \"ubc-scanned-sticky-cards\",\n",
    "]\n",
    "# The threshold calculated from your previous run (Mean FP Score)\n",
    "CUTOFF_SCORE = 0.6926\n",
    "\n",
    "IOU_THRESHOLD = 0.5  # IoU required to call it a TP\n",
    "\n",
    "# ============================================================\n",
    "# UTILITIES\n",
    "# ============================================================\n",
    "def normalize_name(fname):\n",
    "    \"\"\"Strips paths to ensure matching works.\"\"\"\n",
    "    return os.path.basename(fname) if fname else None\n",
    "\n",
    "def polygons_to_mask(polygons, height, width):\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    for poly in polygons:\n",
    "        if not poly: continue\n",
    "        try:\n",
    "            pts = np.array(poly, dtype=np.int32).reshape(-1, 2)\n",
    "            cv2.fillPoly(mask, [pts], 1)\n",
    "        except: continue\n",
    "    return mask\n",
    "\n",
    "def seg_to_mask(segmentation, height, width):\n",
    "    if segmentation is None or not segmentation:\n",
    "        return np.zeros((height, width), dtype=np.uint8)\n",
    "    if isinstance(segmentation, list):\n",
    "        if isinstance(segmentation[0], (int, float)): return np.zeros((height, width), dtype=np.uint8)\n",
    "        return polygons_to_mask(segmentation, height, width)\n",
    "    if isinstance(segmentation, dict):\n",
    "        try:\n",
    "            from pycocotools import mask as mask_utils\n",
    "            return mask_utils.decode(segmentation).astype(np.uint8)\n",
    "        except: return np.zeros((height, width), dtype=np.uint8)\n",
    "    return np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "def mask_iou(mask1, mask2):\n",
    "    inter = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    return float(inter) / float(union) if union > 0 else 0.0\n",
    "\n",
    "# ============================================================\n",
    "# MAIN LOOP\n",
    "# ============================================================\n",
    "print(f\"Analyzing impact of raising Confidence Threshold to: {CUTOFF_SCORE}\\n\")\n",
    "print(f\"{'DATASET':<25} | {'TOTAL TPs':<10} | {'LOST TPs':<10} | {'% LOST':<10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "total_tps_global = 0\n",
    "lost_tps_global = 0\n",
    "\n",
    "for dataset_name in datasets_to_eval:\n",
    "    dataset_path = os.path.join(root_dataset, dataset_name)\n",
    "    gt_file = os.path.join(dataset_path, \"instances_default.json\")\n",
    "    \n",
    "    # Try finding sam3 results\n",
    "    pred_file = os.path.join(dataset_path, \"sam3_results_tiled.json\")\n",
    "    if not os.path.exists(pred_file):\n",
    "        pred_file = os.path.join(dataset_path, \"sam3_results.json\")\n",
    "\n",
    "    if not os.path.exists(gt_file) or not os.path.exists(pred_file):\n",
    "        continue\n",
    "\n",
    "    # Load JSONs\n",
    "    with open(gt_file, 'r') as f: gt = json.load(f)\n",
    "    with open(pred_file, 'r') as f: pred = json.load(f)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # MAPPING LOGIC (Same as before)\n",
    "    # -------------------------------------------------\n",
    "    gt_id_to_info = {}\n",
    "    for im in gt.get(\"images\", []):\n",
    "        norm_name = normalize_name(im[\"file_name\"])\n",
    "        gt_id_to_info[im[\"id\"]] = {\n",
    "            \"file_name\": norm_name,\n",
    "            \"height\": im[\"height\"],\n",
    "            \"width\": im[\"width\"]\n",
    "        }\n",
    "\n",
    "    pred_id_to_filename = {im[\"id\"]: normalize_name(im[\"file_name\"]) for im in pred.get(\"images\", [])}\n",
    "\n",
    "    # Group by File\n",
    "    gt_by_file = defaultdict(list)\n",
    "    for ann in gt.get(\"annotations\", []):\n",
    "        img_id = ann.get(\"image_id\")\n",
    "        if img_id in gt_id_to_info:\n",
    "            gt_by_file[gt_id_to_info[img_id][\"file_name\"]].append(ann)\n",
    "\n",
    "    pred_by_file = defaultdict(list)\n",
    "    for ann in pred.get(\"annotations\", []):\n",
    "        fname = normalize_name(ann.get(\"file_name\"))\n",
    "        if not fname:\n",
    "            fname = pred_id_to_filename.get(ann.get(\"image_id\"))\n",
    "        if fname:\n",
    "            pred_by_file[fname].append(ann)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # CALCULATE TP & LOST TP\n",
    "    # -------------------------------------------------\n",
    "    dataset_tp_count = 0\n",
    "    dataset_lost_tp_count = 0\n",
    "    \n",
    "    # Only process files that exist in both\n",
    "    common_files = set(gt_by_file.keys()).intersection(pred_by_file.keys())\n",
    "\n",
    "    for file_name in common_files:\n",
    "        gt_objs = gt_by_file[file_name]\n",
    "        pred_objs = pred_by_file[file_name]\n",
    "        \n",
    "        if not pred_objs: continue\n",
    "\n",
    "        # Get dims\n",
    "        # (A bit hacky lookup but works given logic above)\n",
    "        img_info = next(v for v in gt_id_to_info.values() if v[\"file_name\"] == file_name)\n",
    "        H, W = img_info[\"height\"], img_info[\"width\"]\n",
    "\n",
    "        # GT Masks\n",
    "        gt_masks = [seg_to_mask(g.get(\"segmentation\"), H, W) for g in gt_objs]\n",
    "        \n",
    "        # Preds (Sorted by score)\n",
    "        pred_data = []\n",
    "        for p in pred_objs:\n",
    "            mask = seg_to_mask(p.get(\"segmentation\"), H, W)\n",
    "            score = p.get(\"score\", 0.0)\n",
    "            pred_data.append({\"mask\": mask, \"score\": score})\n",
    "        \n",
    "        pred_data.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "        matched_gt_indices = set()\n",
    "\n",
    "        # Match TPs\n",
    "        for p in pred_data:\n",
    "            p_mask = p[\"mask\"]\n",
    "            best_iou = 0.0\n",
    "            best_gt_idx = None\n",
    "\n",
    "            for i, g_mask in enumerate(gt_masks):\n",
    "                if i in matched_gt_indices: continue\n",
    "                iou = mask_iou(p_mask, g_mask)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = i\n",
    "            \n",
    "            # CHECK IF TP\n",
    "            if best_iou >= IOU_THRESHOLD:\n",
    "                matched_gt_indices.add(best_gt_idx)\n",
    "                dataset_tp_count += 1\n",
    "                \n",
    "                # KEY CHECK: Is this TP score below our cutoff?\n",
    "                if p[\"score\"] <= CUTOFF_SCORE:\n",
    "                    dataset_lost_tp_count += 1\n",
    "\n",
    "    # Stats for this dataset\n",
    "    pct_lost = (dataset_lost_tp_count / dataset_tp_count * 100) if dataset_tp_count > 0 else 0.0\n",
    "    \n",
    "    print(f\"{dataset_name:<25} | {dataset_tp_count:<10} | {dataset_lost_tp_count:<10} | {pct_lost:.1f}%\")\n",
    "\n",
    "    total_tps_global += dataset_tp_count\n",
    "    lost_tps_global += dataset_lost_tp_count\n",
    "\n",
    "# ============================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================\n",
    "print(\"-\" * 65)\n",
    "if total_tps_global > 0:\n",
    "    global_pct = (lost_tps_global / total_tps_global * 100)\n",
    "    print(f\"TOTAL TPs FOUND:     {total_tps_global}\")\n",
    "    print(f\"TPs LOST (<= {CUTOFF_SCORE}): {lost_tps_global}\")\n",
    "    print(f\"GLOBAL LOSS RATE:    {global_pct:.2f}%\")\n",
    "else:\n",
    "    print(\"No True Positives found in any dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e27cf63-897c-4e41-a176-07da0a3f7441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
